# from datetime import datetime, timedelta
# import statsmodels.api as sm
# import pandas as pd
# from scipy import stats



# # Event data
# events = [

#     {"name": "Russia-Crimea Annexation", "start_date": "3/11/2014", "end_date": "3/25/2014"},
#     {"name": "ECB QE Announcement",  "start_date": "1/15/2015", "end_date": "1/29/2015"},
#     {"name": "Brexit Vote", "start_date": "6/16/2016", "end_date": "6/30/2016"},
#     {"name": "COVID-19 Pandemic", "start_date": "3/4/2020", "end_date": "3/18/2020"},
#     {"name": "Russia-Ukraine War",  "start_date": "2/17/2022", "end_date": "3/3/2022"}
# ]


# def compute_expected_and_abnormal_returns(asset_name, event_start, event_end):
#     asset_data = index_returns[asset_name]
#     all_expected_returns = []
#     all_abnormal_returns = []
 
#     for indicator in indicator_mapping.get(asset_name, []):
#         indicator_data = indicators_data[indicator]
#         subset_data = indicator_data[event_start:event_end]

#         if subset_data.empty:
#             print(f"Warning: No data found for {asset_name} between {event_start} and {event_end}. Analysis might be incomplete.")
#             continue
        
#         X = indicator_data[event_start:event_end]
#         X = sm.add_constant(X)
#         y = asset_data[event_start:event_end]

        
#         # Before the regression model fit
#         y, X = y.align(X, join='inner')
#         model = sm.OLS(y, X).fit()
        
#         # model = sm.OLS(y, X).fit()

#         event_window = asset_data[event_start:event_end]
#         expected_returns = model.predict(sm.add_constant(indicator_data[event_start:event_end]))
#         abnormal_returns = event_window - expected_returns

#         all_expected_returns.append(expected_returns)
#         all_abnormal_returns.append(abnormal_returns)
        
#     # Geometrically compound the returns
#     geo_expected_returns = (1 + pd.concat(all_expected_returns)).cumprod().iloc[-1] - 1
#     geo_abnormal_returns = (1 + pd.concat(all_abnormal_returns)).cumprod().iloc[-1] - 1
    
#      # Compute sigma (standard deviation of abnormal returns during the estimation window)
#     sigma = pd.concat(all_abnormal_returns).std()

#     return geo_expected_returns, geo_abnormal_returns, sigma,model

# def calculate_significance(car, sigma, T):
#     # Calculate SE(CAR)
#     se_car = (T ** 0.5) * sigma

#     # Calculate the test statistic
#     z = car / se_car

#     # Determine the p-value
#     p_value = 2 * (1 - stats.norm.cdf(abs(z)))

#     significance = "significant" if p_value < 0.05 else "not significant"
#     return significance, p_value

# def analyze_all_asset_classes(event_name, event_start, event_end):
#     results = {}
    
#     models = {}

#     for asset in readable_names:
#         if asset != 'Sentiment Score': 
#             expected, abnormal, sigma, model  = compute_expected_and_abnormal_returns(asset, event_start, event_end)
            
#             models[asset] = model
            
#             T = (event_end - event_start).days + 1
#             significance, p_value = calculate_significance(abnormal, sigma, T)
            
#             results[asset] = {
#                 'Expected Returns': expected,
#                 'Abnormal Returns': abnormal,
#                 'Significance': significance,
#                 'P-value': p_value
#             }
            
#     return pd.DataFrame(results).T

# date_format = "%m/%d/%Y"

# dfs_to_concat = []

# for event in events:
#     start_date = datetime.strptime(event["start_date"], date_format).date()
#     end_date = datetime.strptime(event["end_date"], date_format).date()

#     # Get the results for the current event
#     event_df = analyze_all_asset_classes(event["name"], start_date, end_date)
#     event_df.index = pd.MultiIndex.from_product([[event["name"]], event_df.index])
    
#     # Append the event_df to the list of DataFrames
#     dfs_to_concat.append(event_df)

# # Concatenate all the dataframes
# final_df = pd.concat(dfs_to_concat)

# final_df['Expected Returns'] = final_df['Expected Returns'].apply(lambda x: f"{x*100:.2f}%")
# final_df['Abnormal Returns'] = final_df['Abnormal Returns'].apply(lambda x: f"{x*100:.2f}%")
# final_df['P-value'] = final_df['P-value'].apply(lambda x: f"{x:.5f}")

# final_df
